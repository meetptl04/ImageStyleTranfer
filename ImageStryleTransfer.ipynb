{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meetptl04/ImageStyleTranfer/blob/main/ImageStryleTransfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mjh-bWKuh-G6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rlu0rqe_qepR"
      },
      "source": [
        "# Image Processing Class\n",
        "### The `ImageProcessing` class provides static methods for loading and processing images for neural network input, and for converting processed images back to a viewable format. Specifically, it resizes and normalizes images for VGG19 and performs de-normalization for display."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8o9zGlHh_zD"
      },
      "outputs": [],
      "source": [
        "# Image Processing Class\n",
        "class ImageProcessing:\n",
        "    @staticmethod\n",
        "    def load_and_process_img(path_to_img):\n",
        "        max_dim = 512\n",
        "        img = tf.keras.preprocessing.image.load_img(path_to_img)\n",
        "        img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "        long = max(img.shape[:-1])\n",
        "        scale = max_dim / long\n",
        "        img = tf.image.resize(img, (round(img.shape[0] * scale), round(img.shape[1] * scale)))\n",
        "        img = tf.keras.applications.vgg19.preprocess_input(img)\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        return img\n",
        "\n",
        "    @staticmethod\n",
        "    def deprocess_img(processed_img):\n",
        "        x = processed_img.copy()\n",
        "        if len(x.shape) == 4:\n",
        "            x = np.squeeze(x, 0)\n",
        "        x[:, :, 0] += 103.939\n",
        "        x[:, :, 1] += 116.779\n",
        "        x[:, :, 2] += 123.68\n",
        "        x = x[:, :, ::-1]\n",
        "        x = np.clip(x, 0, 255).astype('uint8')\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPgHVAcGqgIV"
      },
      "source": [
        "# Loss Function Class\n",
        "### This class defines a model that calculates the style and content loss for image style transfer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJZsbm7oh_wM"
      },
      "outputs": [],
      "source": [
        "# Loss Functions Class\n",
        "class LossFunctions:\n",
        "    @staticmethod\n",
        "    def get_content_loss(base_content, target):\n",
        "        return tf.reduce_mean(tf.square(base_content - target))\n",
        "\n",
        "    @staticmethod\n",
        "    def gram_matrix(input_tensor):\n",
        "        channels = int(input_tensor.shape[-1])\n",
        "        a = tf.reshape(input_tensor, [-1, channels])\n",
        "        n = tf.shape(a)[0]\n",
        "        gram = tf.matmul(a, a, transpose_a=True)\n",
        "        return gram / tf.cast(n, tf.float32)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_style_loss(base_style, gram_target):\n",
        "        height, width, channels = base_style.get_shape().as_list()\n",
        "        gram_style = LossFunctions.gram_matrix(base_style)\n",
        "        return tf.reduce_mean(tf.square(gram_style - gram_target))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My9qw_QetFlU"
      },
      "source": [
        "# VGG Model Class\n",
        "### The `VGGModel` class initializes a VGG19 model pre-trained on ImageNet, extracts feature representations for content and style images, and provides methods to obtain these features for style transfer tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_FPvQQeh_ta"
      },
      "outputs": [],
      "source": [
        "# VGG Model Class\n",
        "class VGGModel:\n",
        "    def __init__(self):\n",
        "        self.model = self._get_model()\n",
        "\n",
        "    def _get_model(self):\n",
        "        vgg = VGG19(include_top=False, weights='imagenet')\n",
        "        vgg.trainable = False\n",
        "\n",
        "        content_layers = ['block5_conv2']\n",
        "        style_layers = ['block1_conv1', 'block2_conv1',\n",
        "                        'block3_conv1', 'block4_conv1',\n",
        "                        'block5_conv1']\n",
        "\n",
        "        content_output = [vgg.get_layer(layer).output for layer in content_layers]\n",
        "        style_outputs = [vgg.get_layer(layer).output for layer in style_layers]\n",
        "\n",
        "        model_outputs = style_outputs + content_output\n",
        "\n",
        "        return Model(vgg.input, model_outputs)\n",
        "\n",
        "    def get_feature_representations(self, content_path, style_path):\n",
        "        content_image = ImageProcessing.load_and_process_img(content_path)\n",
        "        style_image = ImageProcessing.load_and_process_img(style_path)\n",
        "\n",
        "        # Extract feature representations\n",
        "        content_features = self.model(content_image)[-1]\n",
        "        style_features = self.model(style_image)[:-1]\n",
        "\n",
        "        return style_features, content_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBaEdbLJqmQn"
      },
      "source": [
        "# Style Transfer Class\n",
        "### The `StyleTransfer` class handles the process of applying style transfer to an image using a VGG19 model. It computes losses for style and content features, calculates gradients to update the image, and iteratively optimizes the image to match the style of one image and the content of another. It provides methods to compute losses and gradients, and to perform style transfer over a specified number of iterations, returning the final stylized image and its associated loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAuQBRtjh_qS"
      },
      "outputs": [],
      "source": [
        "# Style Transfer Class\n",
        "class StyleTransfer:\n",
        "    def __init__(self, vgg_model, style_weight=1e-2, content_weight=1e3):\n",
        "        self.vgg_model = vgg_model\n",
        "        self.style_weight = style_weight\n",
        "        self.content_weight = content_weight\n",
        "\n",
        "    def compute_loss(self, init_image, gram_style_features, content_features):\n",
        "        model_outputs = self.vgg_model.model(init_image)\n",
        "\n",
        "        style_output_features = model_outputs[:len(gram_style_features)]\n",
        "        content_output_features = model_outputs[len(gram_style_features):]\n",
        "\n",
        "        style_score = 0\n",
        "        content_score = 0\n",
        "\n",
        "        weight_per_style_layer = 1.0 / float(len(gram_style_features))\n",
        "        for target_style, comb_style in zip(gram_style_features, style_output_features):\n",
        "            style_score += weight_per_style_layer * LossFunctions.get_style_loss(comb_style[0], target_style)\n",
        "\n",
        "        weight_per_content_layer = 1.0 / float(len(content_features))\n",
        "        for target_content, comb_content in zip(content_features, content_output_features):\n",
        "            content_score += weight_per_content_layer * LossFunctions.get_content_loss(comb_content[0], target_content)\n",
        "\n",
        "        style_score *= self.style_weight\n",
        "        content_score *= self.content_weight\n",
        "\n",
        "        loss = style_score + content_score\n",
        "        return loss, style_score, content_score\n",
        "\n",
        "    def compute_grads(self, init_image, gram_style_features, content_features):\n",
        "        with tf.GradientTape() as tape:\n",
        "            all_loss = self.compute_loss(init_image, gram_style_features, content_features)\n",
        "        total_loss = all_loss[0]\n",
        "        return tape.gradient(total_loss, init_image), all_loss\n",
        "\n",
        "    def run_style_transfer(self, content_path, style_path, num_iterations=1000):\n",
        "        style_features, content_features = self.vgg_model.get_feature_representations(content_path, style_path)\n",
        "        gram_style_features = [LossFunctions.gram_matrix(style_feature) for style_feature in style_features]\n",
        "\n",
        "        init_image = ImageProcessing.load_and_process_img(content_path)\n",
        "        init_image = tf.Variable(init_image, dtype=tf.float32)\n",
        "\n",
        "        opt = tf.optimizers.Adam(learning_rate=5.0, beta_1=0.99, epsilon=1e-1)\n",
        "\n",
        "        iter_count = 1\n",
        "        best_loss, best_img = float('inf'), None\n",
        "\n",
        "        norm_means = np.array([103.939, 116.779, 123.68])\n",
        "        min_vals = -norm_means\n",
        "        max_vals = 255 - norm_means\n",
        "\n",
        "        for i in range(num_iterations):\n",
        "            grads, all_loss = self.compute_grads(init_image, gram_style_features, content_features)\n",
        "            loss, style_score, content_score = all_loss\n",
        "            opt.apply_gradients([(grads, init_image)])\n",
        "            clipped = tf.clip_by_value(init_image, min_vals, max_vals)\n",
        "            init_image.assign(clipped)\n",
        "\n",
        "            if loss < best_loss:\n",
        "                best_loss = loss\n",
        "                best_img = ImageProcessing.deprocess_img(init_image.numpy())\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print(f'Iteration: {i}, Total loss: {loss}, Style loss: {style_score}, Content loss: {content_score}')\n",
        "\n",
        "        return best_img, best_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO3L51t_qpV1"
      },
      "source": [
        "# Visualization Class\n",
        "### The Visualization class provides static methods to display images, including showing final results and images from file paths, using Matplotlib for visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mNp01jFMpItV",
        "outputId": "ff012854-c09a-41f4-a124-9ef825b3d443"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "class Visualization:\n",
        "    @staticmethod\n",
        "    def show_results(best_img):\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.imshow(best_img)\n",
        "        plt.title('Final Image')\n",
        "        plt.axis('off')  # Hide axes\n",
        "        plt.show()\n",
        "\n",
        "    @staticmethod\n",
        "    def show_image_matplotlib(image_path):\n",
        "        try:\n",
        "            img = mpimg.imread(image_path)\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            plt.imshow(img)\n",
        "            plt.axis('off')  # Hide axes\n",
        "            plt.show()\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Initialize the classes\n",
        "vgg_model = VGGModel()\n",
        "style_transfer = StyleTransfer(vgg_model)\n",
        "visualizer = Visualization()\n",
        "\n",
        "original_image = '/content/the-starry-night.jpg'  # Replace with your image path\n",
        "style_image = '/content/Fantasy-Garden.png'\n",
        "\n",
        "# Run the style transfer\n",
        "best_img, best_loss = style_transfer.run_style_transfer(original_image, style_image)\n",
        "\n",
        "# Display images\n",
        "visualizer.show_image_matplotlib(original_image)\n",
        "visualizer.show_image_matplotlib(style_image)\n",
        "\n",
        "# Display the resulting image\n",
        "visualizer.show_results(best_img)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMn0IiH4+hwvA8mHWgC9iUx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}